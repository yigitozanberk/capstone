---
title: "SwiftKey Capstone Proj. Milestone Report"
author: "Yigit Ozan Berk"
date: "11/9/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initiation
```{r}
library(quanteda)
library(dplyr)
library(stringr)
library(readtext)
library(spacyr)
library(ggplot2)
library(wordcloud)
library(data.table)
```

# Downloading Data

The dataset can be downloaded from a link given in the course website. [https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip]  

The unzipped file contains a directory called final, then a subdirectory called en_US, which contains the texts.

There are 3 text files.
* en_US.blogs.txt - text from blog posts
* en_US.news.txt - text from news articles
* en_US.twitter.txt - tweets on Twitter

# Introduction

The goal here to display the initial data exploration, and show I am on the track to extablishing my algorithm. 

```{r}
numwords <- system("wc -w *.txt", intern=TRUE)  # intern=TRUE to return output  
numlines <- system("wc -l *.txt", intern=TRUE)
numbytes <- system("wc -c *.txt", intern=TRUE)

# number of words for each dataset
blog.numwords <- as.numeric(gsub('[^0-9]', '', numwords[1]))
news.numwords <- as.numeric(gsub('[^0-9]', '', numwords[2]))
twit.numwords <- as.numeric(gsub('[^0-9]', '', numwords[3]))

# number of lines for each dataset
blog.numlines <- as.numeric(gsub('[^0-9]', '', numlines[1]))
news.numlines <- as.numeric(gsub('[^0-9]', '', numlines[2]))
twit.numlines <- as.numeric(gsub('[^0-9]', '', numlines[3]))

# number of bytes for each dataset
blog.numbytes <- as.numeric(gsub('[^0-9]', '', numbytes[1]))
news.numbytes <- as.numeric(gsub('[^0-9]', '', numbytes[2]))
twit.numbytes <- as.numeric(gsub('[^0-9]', '', numbytes[3]))

words = rbind(blog.numwords, news.numwords, twit.numwords)
lines = rbind(blog.numlines, news.numlines, twit.numlines)
bytes = rbind(blog.numbytes, news.numbytes, twit.numbytes)

data.frame(words = words, lines= lines, Mb = bytes/1000000, 
           row.names = c("blog", "news", "twit"))
```

For memory storage limitations, only %15 random entries from each dataset is used for calculations.

Twitter text
```{r}
con <- file("./en_US.twitter.txt", "r") 
twit = readLines(con, skipNul = T)
close(con)

#takin 15% of data for memory reasons
set.seed(1)
x = sample(2360148, 350000, replace = F)

train = twit[x]

TW <- corpus(train)
rm(con, train, twit, x)
summary(TW, 5)
```

Blog text
```{r}
con <- file("./en_US.blogs.txt", "r") 
blog = readLines(con, skipNul = T)
close(con)

#takin 15% of data for memory reasons
set.seed(12345)
x = sample(899288, 135000, replace = F)

train = blog[x]

BG <- corpus(train)
rm(con, train, blog, x)
summary(BG, 5)
```

News text

```{r}
# 1010242
con <- file("./en_US.news.txt", "r") 
news = readLines(con, skipNul = T)
close(con)

#takin 15% of data for memory reasons
set.seed(10000)
x = sample(1010242, 150000, replace = F)

train = news[x]

NS <- corpus(train)
rm(con, train, news, x)
summary(NS, 5)
```



# Visualize Word Frequency


```{r}
BG.uni = getTables(dat = BG, ng = 1)
set.seed(100)
textplot_wordcloud(BG.uni, min_count = 3000, random_order = FALSE,
                   rotation = .25,
                   color = RColorBrewer::brewer.pal(8, "Dark2"))
```


1. create frequency tables and n-grams
```{r}
getFreqs = function(dat, ng) {
        dat.dfm = dfm(dat, ngrams = ng, remove_punct = T, remove_numbers = T,
                      remove = stopwords("english"))
        dat.freq = docfreq(dat.dfm)
        dat.freq = dat.freq[sort(names(dat.freq))] 
        return(dat.freq)
}

getTables = function(dat, ng) {
        ngrams = getFreqs(dat = dat, ng = ng)
        ngrams_dt = data.table(ngram = names(ngrams), freq = ngrams)
        return(ngrams_dt)
}


```

unigram, bigram, and trigrams

```{r}
unigs = getTables(BG, 1)
bigrs = getTables(BG, 2)
trigs = getTables(BG, 3)
```


Probs of words completing OBSERVED trigrams
```{r}
gamma2 <- 0.5  # bigram discount
gamma3 <- 0.5  # trigram discount
bigPre <- 'is_book'

## Returns a two column data.frame of observed trigrams that start with the
## bigram prefix (bigPre) in the first column named ngram and
## frequencies/counts in the second column named freq. If no observed trigrams
## that start with bigPre exist, an empty data.frame is returned.
##
## bigPre -  single-element char array of the form w2_w1 which are the first 
##           two words of the trigram we are predicting the tail word of
## trigrams - 2 column data.table. The first column: ngram,
##            contains all the trigrams in the corpus. The second column:
##            freq, contains the frequency/count of each trigram.
getODTrigs = function(bigPre, trigrams) {
    tri.obs = data.frame(ngrams = vector(mode = 'character', length = 0),
                          freq = vector(mode = 'integer', length = 0))
    regex = sprintf("%s%s%s", "^", bigPre, "_")
    indices = grep(regex, trigrams$ngram)
    if(length(indices > 0)) {
        tri.obs = trigrams[indices, ]
    }
    return(tri.obs)
}

#mikes's code
getObsTrigs <- function(bigPre, trigrams) {
    trigs.winA <- data.frame(ngrams=vector(mode = 'character', length = 0),
                             freq=vector(mode = 'integer', length = 0))
    regex <- sprintf("%s%s%s", "^", bigPre, "_")
    trigram_indices <- grep(regex, trigrams$ngram)
    if(length(trigram_indices) > 0) {
        trigs.winA <- trigrams[trigram_indices, ]
    }
    
    return(trigs.winA)
}

## Returns a two column data.frame of observed trigrams that start with bigram
## prefix bigPre in the first column named ngram and the probabilities
## q_bo(w_i | w_i-2, w_i-1) in the second column named prob calculated from
## eqn 12. If no observed trigrams starting with bigPre exist, NULL is returned.
##
## obsTrigs - 2 column data.frame or data.table. The first column: ngram,
##            contains all the observed trigrams that start with the bigram
##            prefix bigPre which we are attempting to the predict the next
##            word of in a give phrase. The second column: freq, contains the
##            frequency/count of each trigram.
## bigrs - 2 column data.frame or data.table. The first column: ngram,
##         contains all the bigrams in the corpus. The second column:
##         freq, contains the frequency/count of each bigram.
## bigPre -  single-element char array of the form w2_w1 which are first two
##           words of the trigram we are predicting the tail word of
## triDisc - amount to discount observed trigrams
getODTProbs = function(obsTrigs, bigrs, bigPre, triDisc = 0.5) {
    #return NULL if no trigrams starting with bigPre are observed
    if(nrow(obsTrigs) <1) return(NULL)
    #get total count of the observed trigrams
    obsCount = filter(bigrs, ngram == bigPre)$freq
    obsTrigProbs = mutate(obsTrigs, freq = ((freq - triDisc)/obsCount))
    colnames(obsTrigProbs) = c("ngram", "prob")
    
    return(obsTrigProbs)
}

#Mike's code
getObsTriProbs <- function(obsTrigs, bigrs, bigPre, triDisc=0.5) {
    if(nrow(obsTrigs) < 1) return(NULL)
    obsCount <- filter(bigrs, ngram==bigPre)$freq[1]
    obsTrigProbs <- mutate(obsTrigs, freq=((freq - triDisc) / obsCount))
    colnames(obsTrigProbs) <- c("ngram", "prob")
    
    return(obsTrigProbs)
}

obs_trigs <- getODTrigs(bigPre, trigs)  # get trigrams and counts
# convert counts to probabilities
qbo_obs_trigrams <- getODTProbs(obs_trigs, bigrs, bigPre, gamma3)
qbo_obs_trigrams
```


Find UNOBSERVED trigram tail words
```{r}
## Returns a character vector which are the tail words of unobserved trigrams
## that start with the first two words of obsTrigs (aka the bigram prefix).
## These are the words w in the set B(w_i-2, w_i-1) as defined in the section
## describing the details of equation 17.
##
## obsTrigs - character vector of observed trigrams delimited by _ of the form:
##            w3_w2_w1 where w3_w2 is the bigram prefix
## unigs - 2 column data.frame of all the unigrams in the corpus:
##         ngram = unigram
##         freq = frequency/count of each unigram
getUODTTails = function(obsTrigs, unigs) {
    tails = str_split_fixed(obsTrigs, "_", 3)[, 3]
    unobs_tails = unigs[!(unigs$ngram %in% tails), ]$ngram
    return(unobs_tails)
}


#mike's code
getUnobsTrigTails <- function(obsTrigs, unigs) {
    obs_trig_tails <- str_split_fixed(obsTrigs, "_", 3)[, 3]
    unobs_trig_tails <- unigs[!(unigs$ngram %in% obs_trig_tails), ]$ngram
    return(unobs_trig_tails)
}

unobs_trig_tails <- getUODTTails(obs_trigs$ngram, unigs)
head(unobs_trig_tails, 10)
```

Calculate discounted probability mass at bigram lvl
```{r}
## Returns the total probability mass discounted from all observed bigrams
## calculated from equation 14.  This is the amount of probability mass which
## is redistributed to UNOBSERVED bigrams. If no bigrams starting with
## unigram$ngram[1] exist, 0 is returned.
##
## unigram - single row, 2 column frequency table. The first column: ngram,
##           contains the w_i-1 unigram (2nd word of the bigram prefix). The
##           second column: freq, contains the frequency/count of this unigram.
## bigrams - 2 column data.frame or data.table. The first column: ngram,
##           contains all the bigrams in the corpus. The second column:
##           freq, contains the frequency or count of each bigram.
## bigDisc - amount to discount observed bigrams
getAlphaBi = function(unigram, bigrams, bigDisc = 0.5) {
    regex = sprintf("%s%s%s", "^", unigram$ngram[1], "_")
    bgrs_with_unig = bigrams[grep(regex, bigrams$ngram), ]
    if(nrow(bgrs_with_unig) < 1) return(0)
    alphaBi = 1 - (sum(bgrs_with_unig$freq - bigDisc) / unigram$freq)
    return(alphaBi)
}
#returns 0 if no observed bigrams

#mike's code
getAlphaBigram <- function(unigram, bigrams, bigDisc=0.5) {
    # get all bigrams that start with unigram
    regex <- sprintf("%s%s%s", "^", unigram$ngram[1], "_")
    bigsThatStartWithUnig <- bigrams[grep(regex, bigrams$ngram),]
    if(nrow(bigsThatStartWithUnig) < 1) return(0)
    alphaBi <- 1 - (sum(bigsThatStartWithUnig$freq - bigDisc) / unigram$freq)
    
    return(alphaBi)
}

unig <- str_split(bigPre, "_")[[1]][2]
unig <- unigs[unigs$ngram == unig,]
alpha_big <- getAlphaBi(unig, bigrs, gamma2)
alpha_big
```

Calculate backed-off probabilities q_bo for bigrams
```{r}
## Returns a character vector of backed off bigrams of the form w2_w1. 
## These are all the (w_i-1, w) bigrams where w_i-1 is the tail word of the bigram
## prefix bigPre and w are the tail words of unobserved bigrams that start with
## w_i-1.
##
## bigPre - single-element char array of the form w2_w1 which are first two
##          words of the trigram we are predicting the tail word of
## unobsTrigTails - character vector that are tail words of unobserved trigrams
getBOBigrs = function(bigPre, UODTrigTails) {
    w_i_1 = str_split(bigPre, "_")[[1]][2]
    boBigrams = paste(w_i_1, UODTrigTails, sep = "_")
    return(boBigrams)
}

#mike's code
getBoBigrams <- function(bigPre, unobsTrigTails) {
    w_i_minus1 <- str_split(bigPre, "_")[[1]][2]
    boBigrams <- paste(w_i_minus1, unobsTrigTails, sep = "_")
    return(boBigrams)
}

## Returns a two column data.frame of backed-off bigrams in the first column
## named ngram and their frequency/counts in the second column named freq.
## 
## bigPre -  single-element char array of the form w2_w1 which are first two
##           words of the trigram we are predicting the tail word of
## unobsTrigTails - character vector that are tail words of unobserved trigrams
## bigrs - 2 column data.frame or data.table. The first column: ngram,
##         contains all the bigrams in the corpus. The second column:
##         freq, contains the frequency/count of each bigram.
getODBOBigrs = function(bigPre, UODTrigTails, bigrs) {
    boBigrams = getBOBigrs(bigPre, UODTrigTails)
    obs_bo_bigrs = bigrs[bigrs$ngram %in% boBigrams, ]
    return(obs_bo_bigrs)
}

#mike's code
getObsBoBigrams <- function(bigPre, unobsTrigTails, bigrs) {
    boBigrams <- getBoBigrams(bigPre, unobsTrigTails)
    obs_bo_bigrams <- bigrs[bigrs$ngram %in% boBigrams, ]
    return(obs_bo_bigrams)
}

## Returns a character vector of backed-off bigrams which are unobserved.
##
## bigPre -  single-element char array of the form w2_w1 which are first two
##           words of the trigram we are predicting the tail word of
## unobsTrigTails - character vector that are tail words of unobserved trigrams
## obsBoBigram - data.frame which contains the observed bigrams in a column
##               named ngram
getUODBOBigrs = function(bigPre, UODTrigTails, ODBOBigrs) {
    boBigrs = getBOBigrs(bigPre, UODTrigTails)
    unobs_bigrs = boBigrs[!(boBigrs %in% ODBOBigrs$ngram)]
    return(unobs_bigrs)
}


#mike's code
getUnobsBoBigrams <- function(bigPre, unobsTrigTails, obsBoBigram) {
    boBigrams <- getBoBigrams(bigPre, unobsTrigTails)
    unobs_bigs <- boBigrams[!(boBigrams %in% obsBoBigram$ngram)]
    return(unobs_bigs)
}

## Returns a dataframe of 2 columns: ngram and probs.  Values in the ngram
## column are bigrams of the form: w2_w1 which are observed as the last
## two words in unobserved trigrams.  The values in the prob column are
## q_bo(w1 | w2) calculated from from equation 10.
##
## obsBoBigrams - a dataframe with 2 columns: ngram and freq. The ngram column
##                contains bigrams of the form w1_w2 which are observed bigrams
##                that are the last 2 words of unobserved trigrams (i.e. "backed
##                off" bigrams). The freq column contains integers that are
##                the counts of these observed bigrams in the corpus.
## unigs - 2 column data.frame of all the unigrams in the corpus:
##         ngram = unigram
##         freq = frequency/count of each unigram
## bigDisc - amount to discount observed bigrams
getODBigrsProbs = function(ODBOBigrs, unigs, bigDisc = 0.5) {
    first_words = str_split_fixed(ODBOBigrs$ngram, "_", 2)[ ,1]
    first_word_freqs = unigs[unigs$ngram %in% first_words, ]
    ODBigrsProbs = (ODBOBigrs$freq - bigDisc) / first_word_freqs$freq
    ODBigrsProbs = data.frame(ngram = ODBOBigrs$ngram, prob = ODBigrsProbs)
    
    return(ODBigrsProbs)
}

#mike's code
getObsBigProbs <- function(obsBoBigrams, unigs, bigDisc=0.5) {
    first_words <- str_split_fixed(obsBoBigrams$ngram, "_", 2)[, 1]
    first_word_freqs <- unigs[unigs$ngram %in% first_words, ]
    obsBigProbs <- (obsBoBigrams$freq - bigDisc) / first_word_freqs$freq
    obsBigProbs <- data.frame(ngram=obsBoBigrams$ngram, prob=obsBigProbs)
    
    return(obsBigProbs)
}

## Returns a dataframe of 2 columns: ngram and prob.  Values in the ngram
## column are unobserved bigrams of the form: w2_w1.  The values in the prob
## column are the backed off probability estimates q_bo(w1 | w2) calculated
## from from equation 16.
##
## unobsBoBigrams - character vector of unobserved backed off bigrams
## unigs - 2 column data.frame of all the unigrams in the corpus:
##         ngram = unigram
##         freq = frequency/count of each unigram
## alphaBig - total discounted probability mass at the bigram level
# CHECK
getUODBOBigrsProbs = function(UODBOBigrs, unigs, alphaBig) {
    #unobserved bigram tails
    UODBigrsProbs = str_split_fixed(UODBOBigrs, "_", 2)[, 2]
    w_Aw_i_1 = unigs[!(unigs$ngram %in% UODBigrsProbs), ]
    #dataframe with counts
    UODBigrsProbs = unigs[unigs$ngram %in% UODBigrsProbs, ]
    qD = sum(UODBigrsProbs$freq)
    #probabilities
    UODBigrsProbs = data.frame(ngram = UODBOBigrs, 
                               prob = (alphaBig * UODBigrsProbs$freq / qD))
    return(UODBigrsProbs)
}


#mike's code
getQboUnobsBigrams <- function(unobsBoBigrams, unigs, alphaBig) {
    # get the unobserved bigram tails
    qboUnobsBigs <- str_split_fixed(unobsBoBigrams, "_", 2)[, 2]
    w_in_Aw_iminus1 <- unigs[!(unigs$ngram %in% qboUnobsBigs), ]
    # convert to data.frame with counts
    # PROBLEM HERE, w_in_Aw_iminus1 is not used to get qboUnobsBigs
    qboUnobsBigs <- unigs[unigs$ngram %in% qboUnobsBigs, ]
    denom <- sum(qboUnobsBigs$freq)
    # converts counts to probabilities
    qboUnobsBigs <- data.frame(ngram=unobsBoBigrams,
                               prob=(alphaBig * qboUnobsBigs$freq / denom))
    
    return(qboUnobsBigs)
}

#get backed off bigrams
bo_bigrs = getBOBigrs(bigPre, unobs_trig_tails)
#separate observed bigrams from unobserved bigrams
obs_bo_bigrs = getODBOBigrs(bigPre, unobs_trig_tails, bigrs)
unobs_bo_bigrs = getUODBOBigrs(bigPre, unobs_trig_tails, obs_bo_bigrs)
#qbo
qbo_obs_bigrams = getODBigrsProbs(obs_bo_bigrs, unigs, gamma2)

unig <- str_split(bigPre, "_")[[1]][2]
unig <- unigs[unigs$ngram == unig,]
#qbo redistributed
qbo_unobs_bigrams = getUODBOBigrsProbs(unobs_bo_bigrs, unigs, alpha_big)
qbo_bigrams = rbind(qbo_obs_bigrams, qbo_unobs_bigrams)
head(qbo_bigrams)
```


Checking Bigram Calculations
```{r}
unobs <- qbo_bigrams[-1,]
sum(unobs$prob)
```



Discounted probability mass in trigram level
```{r}
## Returns the total probability mass discounted from all observed trigrams.
## calculated from equation 14. This is the amount of probability mass which is
## redistributed to UNOBSERVED trigrams. If no trigrams starting with
## bigram$ngram[1] exist, 1 is returned.
##
## obsTrigs - 2 column data.frame or data.table. The first column: ngram,
##            contains all the observed trigrams that start with the bigram
##            prefix we are attempting to the predict the next word of. The 
##            second column: freq, contains the frequency/count of each trigram.
## bigram - single row frequency table where the first col: ngram, is the bigram
##          which are the first two words of unobserved trigrams we want to
##          estimate probabilities of (same as bigPre in other functions listed
##          prior) delimited with '_'. The second column: freq, is the
##          frequency/count of the bigram listed in the ngram column.
## triDisc - amount to discount observed trigrams
getAlphaTri = function(obsTrigs, bigram, triDisc = 0.5) {
    if(nrow(obsTrigs) < 1) return(1)
    alphaTri = 1 - sum((obsTrigs$freq - triDisc) / bigram$freq[1])
    
    return(alphaTri)
}

#mike's code
getAlphaTrigram <- function(obsTrigs, bigram, triDisc=0.5) {
    if(nrow(obsTrigs) < 1) return(1)
    alphaTri <- 1 - sum((obsTrigs$freq - triDisc) / bigram$freq[1])
    
    return(alphaTri)
}

bigram <- bigrs[bigrs$ngram %in% bigPre, ]
alpha_trig <- getAlphaTri(obs_trigs, bigram, gamma3)
alpha_trig
```


Calculate UNOBSERVED trigram probabilities
```{r}
## Returns a dataframe of 2 columns: ngram and prob.  Values in the ngram
## column are unobserved trigrams of the form: w3_w2_w1.  The values in the prob
## column are q_bo(w1 | w3, w2) calculated from equation 17.
##
## bigPre -  single-element char array of the form w2_w1 which are first two
##           words of the trigram we are predicting the tail word of
## qboObsBigrams - 2 column data.frame with the following columns -
##                 ngram: observed bigrams of the form w2_w1
##                 probs: the probability estimate for observed bigrams:
##                        qbo(w1 | w2) calc'd from equation 10.
## qboUnobsBigrams - 2 column data.frame with the following columns -
##                   ngram: unobserved bigrams of the form w2_w1
##                   probs: the probability estimate for unobserved bigrams
##                          qbo(w1 | w2) calc'd from equation 16.
## alphaTrig - total discounted probability mass at the trigram level
getUODTrigProbs = function()

#mike's code
getUnobsTriProbs <- function(bigPre, qboObsBigrams,
                             qboUnobsBigrams, alphaTrig) {
    qboBigrams <- rbind(qboObsBigrams, qboUnobsBigrams)
    qboBigrams <- qboBigrams[order(-qboBigrams$prob), ]
    sumQboBigs <- sum(qboBigrams$prob)
    first_bigPre_word <- str_split(bigPre, "_")[[1]][1]
    unobsTrigNgrams <- paste(first_bigPre_word, qboBigrams$ngram, sep="_")
    unobsTrigProbs <- alphaTrig * qboBigrams$prob / sumQboBigs
    unobsTrigDf <- data.frame(ngram=unobsTrigNgrams, prob=unobsTrigProbs)
    
    return(unobsTrigDf)
}

qbo_unobs_trigrams <- getUnobsTriProbs(bigPre, qbo_obs_bigrams,
                                       qbo_unobs_bigrams, alpha_trig)
qbo_unobs_trigrams
```


Get prediction with the highest prob
```{r}
getPredictionMsg <- function(qbo_trigs) {
    # pull off tail word of highest prob trigram
    prediction <- str_split(qbo_trigs$ngram[1], "_")[[1]][3]
    result <- sprintf("%s%s%s%.4f", "highest prob prediction is >>> ", prediction,
                      " <<< which has probability = ", qbo_trigs$prob[1])
    return(result)
}

qbo_trigrams <- rbind(qbo_obs_trigrams, qbo_unobs_trigrams)
qbo_trigrams <- qbo_trigrams[order(-qbo_trigrams$prob), ]  # sort by desc prob
out_msg <- getPredictionMsg(qbo_trigrams)
out_msg
```



testing
```{r}
gamma2=0.7; gamma3=0.7  # initialize new discount rates
bigPre = "is_my"

obs_trigs <- getObsTrigs(bigPre, trigs)
unobs_trig_tails <- getUnobsTrigTails(obs_trigs$ngram, unigs)
bo_bigrams <- getBoBigrams(bigPre, unobs_trig_tails)
# separate bigrams which use eqn 10 and those that use 16
obs_bo_bigrams <- getObsBoBigrams(bigPre, unobs_trig_tails, bigrs)
unobs_bo_bigrams <- getUnobsBoBigrams(bigPre, unobs_trig_tails, obs_bo_bigrams)
# calc obs'd bigram prob's from eqn 10
qbo_obs_bigrams <- getObsBigProbs(obs_bo_bigrams, unigs, gamma2)
# calc alpha_big & unobs'd bigram prob's from eqn 16
unig <- str_split(bigPre, "_")[[1]][2]
unig <- unigs[unigs$ngram == unig,]
alpha_big <- getAlphaBigram(unig, bigrs, gamma2)
# distrib discounted bigram prob mass to unobs bigrams in prop to unigram ML
qbo_unobs_bigrams <- getQboUnobsBigrams(unobs_bo_bigrams, unigs, alpha_big)
# calc trigram probabilities - start with observed trigrams: eqn 12
qbo_obs_trigrams <- getObsTriProbs(obs_trigs, bigrs, bigPre, gamma3)
# finally, calc trigram unobserved probabilities: eqn 17
bigram <- bigrs[bigrs$ngram %in% bigPre, ]
alpha_trig <- getAlphaTrigram(obs_trigs, bigram, gamma3)
qbo_unobs_trigrams <- getUnobsTriProbs(bigPre, qbo_obs_bigrams,
                                       qbo_unobs_bigrams, alpha_trig)
qbo_trigrams <- rbind(qbo_obs_trigrams, qbo_unobs_trigrams)
qbo_trigrams <- qbo_trigrams[order(-qbo_trigrams$prob), ]
getPredictionMsg(qbo_trigrams)
```

